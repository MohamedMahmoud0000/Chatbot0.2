{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R5wrz4pnwOv",
        "outputId": "94b740eb-cb60-4654-bda0-5e000610e3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: Yo.\n",
            "User: ازيك\n",
            "Chatbot: كويس الحمدلله وانتا عامل ايه\n",
            "User: H,i\n",
            "Chatbot: idk what you talking about.\n",
            "User: Hi\n",
            "Chatbot: hi there\n",
            "User: hI\n",
            "Chatbot: مرحبا\n",
            "User: hi\"\n",
            "Chatbot: hi\n",
            "User: \"hi\"\n",
            "Chatbot: hi\n",
            "User: ....hi.....\"\n",
            "Chatbot: hello\n",
            "User: ..Yo \n",
            "Chatbot: idk what you talking about.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import random\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\")\n",
        "GREETING_RESPONSES = [\"hi\", \"hey\", \"hi there\", \"hello\", \"all good\",\"مرحبا\"]\n",
        "\n",
        "knowledge_base = {\n",
        "    \"what is your name\": \"My name is Chatbot.\",\n",
        "    \"how are you\": \"I am doing well, thank you!\",\n",
        "    \"what can you do\": \"I can answer simple questions and engage in basic conversations.\",\n",
        "    \"tell me a joke\": \"Why don't scientists trust atoms? Because they make up everything!\",\n",
        "    \"what is the capital of France\": \"The capital of France is Paris.\",\n",
        "    \"who is the author of Harry Potter\": \"The author of Harry Potter is J.K. Rowling.\",\n",
        "    \"what is the square root of 25\": \"The square root of 25 is 5.\",\n",
        "    \"tell me a fun fact\": \"A crocodile cannot stick its tongue out.\",\n",
        "    \"what is the tallest mountain in the world\": \"The tallest mountain in the world is Mount Everest.\",\n",
        "    \"who painted the Mona Lisa\": \"The Mona Lisa was painted by Leonardo da Vinci.\",\n",
        "    \"whatsup?\": \"I'm good.\",\n",
        "    \"hru man\": \"I'm okay.\",\n",
        "    \"how is life?\": \"Good, thanks!\",\n",
        "    \"so what brought you here?\": \"Nothing, I'm just a bot. What's up?\",\n",
        "    \"i see\": \"Yeah!\",\n",
        "    \"ازيك\" : \"كويس الحمدلله وانتا عامل ايه\",\n",
        "     \"كويس\": \"يا رب دايما\"\n",
        "    \n",
        "}\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_sentence = [lemmatizer.lemmatize(word) for word in word_tokens if word not in stopwords.words('english')]\n",
        "    return filtered_sentence\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = []\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.append(lemma.name())\n",
        "    return set(synonyms)\n",
        "\n",
        "def generate_response(user_input):\n",
        "    user_input = preprocess(user_input)\n",
        "    user_input_str = ' '.join(user_input)\n",
        "    \n",
        "    if greeting(user_input_str):\n",
        "        return greeting(user_input_str)\n",
        "    else:\n",
        "        for question, answer in knowledge_base.items():\n",
        "            if set(user_input).intersection(set(preprocess(question))):\n",
        "                return answer\n",
        "            else:\n",
        "                for word in user_input:\n",
        "                    synonyms = get_synonyms(word)\n",
        "                    if synonyms.intersection(set(preprocess(question))):\n",
        "                        return answer\n",
        "        return \"idk what you talking about.\"\n",
        "\n",
        "def greeting(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)\n",
        "\n",
        "print(\"Chatbot: Yo.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() == 'bye':\n",
        "        print(\"Chatbot: byeeeeeee\")\n",
        "        break\n",
        "    else:\n",
        "        print(\"Chatbot:\", generate_response(user_input))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rUvb2LOCq_A1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}